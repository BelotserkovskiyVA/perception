{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0be132-cf48-40d2-a3bc-59af1f8b9a4a",
   "metadata": {},
   "source": [
    "## Содержание\n",
    "```\n",
    "1 Прямой проход и обратное распространение\n",
    "2 Разбиение набора данных\n",
    "3 Нормализация данных\n",
    "4 Валидация и потеря\n",
    "5 Схождение\n",
    "6 Контрольные точки и ранняя остановка\n",
    "7 Гиперпараметры\n",
    "8 Инвариантность\n",
    "9 Сырые наборы данных\n",
    "10 Сохранение/Восстановление модели\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a69b05-d7fc-48fd-b685-635f8a6edcb7",
   "metadata": {},
   "source": [
    "## 1 Прямой проход и обратное распространение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e097cb-3772-45be-8f85-ab9a9200777b",
   "metadata": {},
   "source": [
    "#### Прямой проход"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af0c34b-0c31-4b95-a35e-8deb6e48a448",
   "metadata": {},
   "source": [
    "<img src=\"images/forward_pass.png\" alt=\"forward\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbf1ad-bbd5-4f3b-8f8c-414ffdbddff7",
   "metadata": {},
   "source": [
    "```\n",
    "    Данные подаются в нейронную сеть пакетами (batch-ами). Пакет может состоять из одного или нескольких выбранных наугад примеров из тренировочных данных.\n",
    "    Тренировочные данные подаются в модель несколько раз. Всякий раз, когда мы подаем все тренировочные данные целиком, это\n",
    "называется эпохой. Каждая эпоха представляет собой отличающуюся случайную перестановку примеров в пакетах – то есть не существует двух эпох с одинаковым порядком следования примеров.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c6ff4-4233-4cc1-9666-89aab00b1edb",
   "metadata": {},
   "source": [
    "#### Историческая справка\n",
    "```\n",
    "    В  ранних нейронных сетях, таких как персептрон и пр., исследователи экспериментировали со способами обновления весов, чтобы получать правильный ответ.\n",
    "    Когда они работали всего с несколькими нейронами и простыми задачами, первым подходом было случайное обновление весов. Кто бы мог подумать, но случайная догадка работала. Однако, такой подход не масштабировался на большое количество нейронов (скажем, тысячи) и реально существующие приложения; на то, чтобы сделать правильную случайную догадку, могли уйти тысячи лет\n",
    "    Следующим логическим шагом было попытаться сделать случайное значение пропорциональным удаленности от правильного значения. Другими словами, чем больше ошибка (удаленнее предсказание), тем больше диапазон случайных значений; и чем ближе, тем меньше диапазон. Это сокращает время поиска (весов нейронной сети) до сотен лет.\n",
    "    Но такой подход не работал с многослойными нейронными сетями. Обнаружилось, что при наличии нескольких слоев эта методика приводит\n",
    "к тому, что \"левая рука\" – один слой – отменяет работу \"правой руки\" – другого слоя.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196b930-f05c-4aa0-a4e1-4314ffb525a0",
   "metadata": {},
   "source": [
    "#### Обратное распространение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc5e7c-a0e3-44c6-ab55-25b03a264ed0",
   "metadata": {},
   "source": [
    "<img src=\"images/back_prop.png\" alt=\"backpropagation\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f8a42d-0a7c-4532-b425-98fb7e017be5",
   "metadata": {},
   "source": [
    "```\n",
    "    После того как каждый пакет тренировочных данных пропущен через модель в прямом направлении и вычислена потеря, потеря распространяется через модель в обратном направлении. Мы идем слой за слоем, обновляя параметры модели (веса и  смещения), начиная с  верхнего слоя (выхода) и  продвигаясь к  нижнему слою (входу).\n",
    "    Общий метод обновления параметров основан на градиентном спуске. Оптимизатор – это имплементация градиентного спуска, задача которого состоит в обновлении параметров для минимизации потери (максимального приближения к  правильному ответу) в последующих пакетах.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575366ae-029d-4288-9d6a-710b8bb3250f",
   "metadata": {},
   "source": [
    "## 2 Разбиение набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6310d9d1-54da-4d5b-8a49-80b9d21ceeca",
   "metadata": {},
   "source": [
    "#### Тренировочный и тестовый наборы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341fea7d-9357-4b40-98fa-45a6de24aa13",
   "metadata": {},
   "source": [
    "<img src=\"images/train_test.png\" alt=\"train_data\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a66464-f5e3-4d09-8fe4-82eed7738ddf",
   "metadata": {},
   "source": [
    "```\n",
    "     По умолчанию будем рассматривать наборы данных, которые достаточно велики и разнообразны, чтобы представлять выборочное распределение (моделируемую популяцию), и очищены (не зашумлены).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea56b50-533e-46be-9715-ee0ac0d4ac3d",
   "metadata": {},
   "source": [
    "```\n",
    "    Имея в своем распоряжении набор данных, следующим шагом будет его разбиение на примеры, которые будут использоваться для тренировки, и те, которые будут использоваться для тестирования (т.н. отложенные). Мы тренируем модель той порцией набора данных, которые являются тренировочными. Если допустить, что тренировочные данные являются хорошим выборочным распределением, то точность на тренировочных данных должна отражать точность, получаемую при развертывании в реально существующей среде (на примерах, не встречавшихся моделью во время тренировки). Но как проверить истинность этого утверждения до того, как модель будет развернута? Отсюда и вытекает предназначение тестовых данных. Мы откладываем часть данных, с помощью которой будем тестировать модель, после того как она будет обучена, чтобы убедиться, что мы получили или не получили нужную точность.\n",
    "    Сколько данных следует откладывать на тренировку и тестирование? Исторически сложилось эмпирическое соотношение 80/20: 80% для тренировки и 20% для тестирования. Но пропорция 90/10 тоже хорошо работает.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a2c4cc-1d44-4311-918e-d1ed62a25104",
   "metadata": {},
   "source": [
    "#### Пример"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e51777-6e02-4b55-8f09-66648da73fce",
   "metadata": {},
   "source": [
    "```\n",
    "    Для классифицирования изображений есть несколько хорошо известных, подготовленных наборов данных, таких как MNIST, CIFAR-10/100*, SVHN, Flowers, Cats vs. Dogs.\n",
    "    Рассмотрим один из них\n",
    "\n",
    "* аббр. от англ. Canadian Institute for Advanced Research – Канадский институт перспективных исследований\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f76445-503a-481e-8d6e-b151f4a2a4b6",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# MNIST\n",
    "\n",
    "# Downloading the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./MNIST/train\", train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./MNIST/test\", train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfce968-5896-4ee4-b0ed-42cbe77ee174",
   "metadata": {},
   "source": [
    "```\n",
    "train_dataset - 60000 imgs\n",
    "test_dataset  - 10000 imgs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d1e656-f3ca-4041-8441-ea231902f2bf",
   "metadata": {},
   "source": [
    "<img src=\"images/MNIST_data.png\" alt=\"mnist_dataset\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193b8858-518e-4813-b89a-24e70afb5842",
   "metadata": {},
   "source": [
    "``` python\n",
    "def encode_label(j):\n",
    "    # 5 -> [[0], [0], [0], [0], [0], [1], [0], [0], [0], [0]]\n",
    "    e = np.zeros((10,1))\n",
    "    e[j] = 1.0\n",
    "    return e\n",
    "\n",
    "def reshape_data(data):\n",
    "    features = [np.reshape(x[0][0].numpy(), (784,1)) for x in data]\n",
    "    #print('features\\n', len(features[0]))\n",
    "    labels = [encode_label(y[1]) for y in data]\n",
    "    #print('labels\\n', len(labels[0]))\n",
    "    return zip(features, labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0397fc6d-524f-468e-b33f-1cc6d91993dd",
   "metadata": {},
   "source": [
    "## 3 Нормализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b2c26c-bc07-4380-afbf-77a42848ff35",
   "metadata": {},
   "source": [
    "#### Нормализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f43cdb5-b0fa-47a0-9525-327c11ea484b",
   "metadata": {},
   "source": [
    "```\n",
    "    Каждое изображение датасета MNIST является 28×28-матрицей целочисленных значений от 0 до 255. Если посмотреть на параметры\n",
    "натренированной модели (веса и смещения), то они представляют очень малые числа, обычно от –1 до 1. Проблема здесь в том, что\n",
    "большие входные значения (вплоть до 255), будут порождать крупные числа по мере их умножения по всем слоям. Поэтому сети потребуется больше времени на то, чтобы усвоить свои оптимальные значения – если она вообще их усвоит.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a1392-71e1-442f-87b0-69eb531c2f91",
   "metadata": {},
   "source": [
    "Поэтому:\n",
    "```python\n",
    "import numpy\n",
    "\n",
    "maxi = np.max(x_train) # 255.0\n",
    "x_train = (x_train / maxi).astype(np.float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161efb5b-745a-410c-9d7a-34979c799fff",
   "metadata": {},
   "source": [
    "#### Стандартизация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea54e93c-f3b5-45f6-9425-05c07e033bfa",
   "metadata": {},
   "source": [
    "```python\n",
    "mean = np.mean(x_train)\n",
    "std = np.std(x_train)\n",
    "x_train = ((x_train – mean) / std).astype(np.float32)\n",
    "\n",
    "# например x_train = ((x_train / 127.5) – 1).astype(np.float32)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd0d39-2f88-4c0e-8ae5-028531ce2c8e",
   "metadata": {},
   "source": [
    "## 4 Валидация и \"потеря\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb5584-18db-48cf-b161-692abeadb8a0",
   "metadata": {},
   "source": [
    "#### Валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b9fca9-91e6-474e-89f2-2b3920474f0c",
   "metadata": {},
   "source": [
    "<img src=\"images/valid.png\" alt=\"validation\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ca97fb-1dd2-4be2-bd65-f0532cdb347e",
   "metadata": {},
   "source": [
    "```\n",
    "    Допустим, тренировка модели занимает несколько часов. Что делать, если мы не хотим ждать до конца тренировки чтобы узнать точность модели? Для этого мы выделяем небольшую часть тренировочных данных, которые называем валидационными данными.\n",
    "    Модель не тренируется с помощью валидационных данных. Вместо этого указанные данные используются после каждой n-ой эпохи для\n",
    "оценивания возможного результата на тестовых данных. Как и тестовые данные, валидационные данные пропускаются через модель\n",
    "без обновления модельных параметров (в режиме предсказательного вывода), после чего измеряются потеря и точность.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef0721-a9b4-48a6-8a74-fc67ca4c313d",
   "metadata": {},
   "source": [
    "```\n",
    "Если набор данных очень мал и  использование еще меньшего объема данных для тренировки оказывает негативное влияние, то можно применить перекрестную валидацию. Вместо того чтобы часть тренировочных данных, на которых модель никогда не будет тренироваться, с самого начала откладывать в сторону, в каждой эпохе выполняется случайная разбивка. В начале каждой эпохи примеры для валидации отбираются в случайном порядке и не используются для тренировки в этой эпохе, а вместо этого используются для валидационного теста. Но поскольку отбор является случайным, некоторые или все примеры будут появляться среди тренировочных данных в других эпохах\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528854cd-ea55-4c5d-b0ff-e9d4a8237d76",
   "metadata": {},
   "source": [
    "<img src=\"images/cross_valid.png\" alt=\"сross_validation\" height=50% width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff3d68b-2443-4667-b9e6-8c7cc8448d8a",
   "metadata": {},
   "source": [
    "#### Потеря"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b206669f-91ca-4592-9588-2f82d45d52fd",
   "metadata": {},
   "source": [
    "```\n",
    "    Ранее все наше внимание было сосредоточено на точности. Но во время тренировки вы увидите еще одну метрику – среднюю по batch-ам потерю (ошибку) как для тренировочных данных, так и для тестовых. В идеале мы хотели бы видеть неуклонное увеличение точности в расчете на\n",
    "эпоху. Но мы также можем увидеть отрезки эпох, для которых точность выходит на плато или даже колеблется.\n",
    "    Важно то, что мы видим стабильное снижение потери. Плато или колебания в этом случае происходят из-за того, что мы находимся\n",
    "рядом с линиями линейной разделимости, или не полностью перешли линию, но приближаемся, о чем свидетельствует уменьшение потери.\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213ac4b9-1d8f-4348-a82e-9be3c9c7931f",
   "metadata": {},
   "source": [
    "```\n",
    "Давайте рассмотрим пример. Допустим, вы создаете классификатор собак и кошек. В выходном слое у вас есть два узла: один для кошек и один для собак. Допустим, что в конкретном batch-е, когда модель неправильно классифицирует собаку как кошку, выходные значения (уровень уверенности) равны 0.6 для кошки и 0.4 для собаки. В последующем batch-е, когда модель снова неправильно классифицирует собаку как кошку, выходные значения равны 0.55 (кошка) и 0.45 (собака). Теперь значения ближе к фундаментальным истинам, и, следовательно, потеря уменьшается, но они все еще не преодолели порог 0.5, поэтому точность пока не изменилась. Затем допустим, что в еще одном последующем пакете выходные значения для изображения собаки равны 0.49 (кошка) и 0.51 (собака); потеря еще больше уменьшилась, и поскольку мы\n",
    "пересекли порог 0.5, точность повысилась.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dab3356-5045-414b-9bb7-d7dc8fbecd25",
   "metadata": {},
   "source": [
    "## 5 Схождение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9cc2b7-80e9-4f3d-9931-d7414094d4af",
   "metadata": {},
   "source": [
    "<img src=\"images/convergence.png\" alt=\"convergence\" height=50% width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0dda43-66c7-49c0-b507-4c37bd0e4aea",
   "metadata": {},
   "source": [
    "```\n",
    "    Ранние предположения о  тренировке заключались в  том, что чем больше раз вводить тренировочные данные в модель, тем выше будет\n",
    "точность. Мы обнаружили, в особенности в более крупных и сложных сетях, что в определенный момент точность будет деградировать. Сегодня мы стремимся достигать схождения на приемлемом локальном оптимуме, основываясь на том, как модель будет использоваться в приложении. Если излишне натренировать нейронную сеть, то может произойти следующее:\n",
    "    1) нейронная сеть становится переподогнанной к тренировочным данным, демонстрируя повышенную точность на тренировочных данных, но показывая деградирующую точность на тестовых данных;\n",
    "    2) в более глубоких нейронных сетях слои будут учиться неравномерно и иметь разные скорости обучения. Отсюда, поскольку\n",
    "некоторые слои продолжают обучаться (работают в направлении схождения), другие уже могут начать расходиться;\n",
    "    3) продолжение тренировки может привести к тому, что нейронная сеть выскочит из одного локального оптимума и начнет сходиться на другом, менее точном.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05314859-1a48-47fd-b2c9-6aa3d7df234d",
   "metadata": {},
   "source": [
    "## 6 Контрольные точки и ранняя остановка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1584d72-ebcd-447a-8472-7be2e8594f31",
   "metadata": {},
   "source": [
    "#### Контрольные точки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bda131-b022-4a52-b6f2-e1f4daf07445",
   "metadata": {},
   "source": [
    "```\n",
    "    Контрольные точки – это периодическое сохранение параметров модели, усвоенных во время тренировки, и  текущих значений гиперпараметров. Для этого есть две причины:\n",
    "     - иметь возможность возобновлять тренировку модели с того места, на котором вы остановились, вместо того чтобы начинать\n",
    "тренировку с самого начала;\n",
    "    - идентифицировать точку в тренировке, где модель показала наилучшие результаты.\n",
    "    Почему же сохранение модельных весов и смещений не будет достаточным? В нейронных сетях значения некоторых гиперпараметров будут динамически изменяться, например скорость усвоения и затухание. Мы хотели бы возобновлять работу с теми же значениями гиперпараметров, которые имелись на момент приостановки тренировки.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6113c31e-f5a6-463e-a849-88ba70aaf5f7",
   "metadata": {},
   "source": [
    "```\n",
    "    Фиксация в контрольной точке происходит в конце эпохи, но следует ли фиксировать в контрольной точке после каждой эпохи? Наверное, нет. Это бывает дорого с точки зрения пространства. Предположим, что модель имеет 25 млн параметров (например, ResNet50), и  каждый параметр является 32-битовым значением с  плавающей точкой (4 байта). Тогда для сохранения каждой контрольной точки потребуется 100 Мб. Через 10 эпох это уже будет 1 Гб дискового пространства.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac95f4f4-b9dd-42a7-aaef-c5a6348f4382",
   "metadata": {},
   "source": [
    "```python\n",
    "# save model\n",
    "torch.save(model.state_dict(), f'weights/best_{cfg_name}_{step}.pth')\n",
    "\n",
    "#load\n",
    "model = My_Net()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f22ff-17e9-4448-924b-978627b80366",
   "metadata": {},
   "source": [
    "```python\n",
    "# save model  not model.state_dict()\n",
    "torch.save(model, 'model.pt')\n",
    "\n",
    "#load\n",
    "model = torch.load('model.pt')\n",
    "```\n",
    "```\n",
    "However in this case, the serialized data is bound to the specific classes and the exact directory structure used, so it can break in various ways when used in other projects, or after some serious refactors.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7161c2-a6dc-4048-ae26-b540bed29523",
   "metadata": {},
   "source": [
    "#### Ранняя остановка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf5ac1-6de9-4924-91f2-f5b9ad9e1060",
   "metadata": {},
   "source": [
    "```\n",
    "    Ранняя остановка, или досрочная остановка, – это задание условия, при котором тренировка завершается раньше установленных пределов (например, числа эпох). Обычно это делается с целью экономии ресурсов и/или предотвращения перетренированности, когда целевой критерий достигнут, такой как уровень точности или схождение на оценочной потере. Например, мы могли бы проводить тренировку в течение 20 эпох, продолжительностью в среднем 30 минут каждая, в общей сложности в течение 10 часов. Но если критерий будет достигнут через 8 эпох, то было бы идеально завершить тренировку, сэкономив 6 часов ресурсов.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbdd4e3-8d1e-43b9-ab67-caae065a82f2",
   "metadata": {},
   "source": [
    "## 7 Гиперпараметры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b83ee73-91c9-47cb-938c-9dd8ca17aa39",
   "metadata": {},
   "source": [
    "```\n",
    "    Гиперпараметры – это параметры, используемые для тренировки модели, но не являющиеся частью самой натренированной модели.\n",
    "После тренировки гиперпараметры больше не существуют. Гиперпараметры используются для улучшения процесса тренировки модели, отвечая на такие вопросы, как:\n",
    "    - сколько времени требуется для тренировки модели?\n",
    "    - как быстро модель сходится?\n",
    "    - находит ли она глобальный оптимум?\n",
    "    - насколько точной является модель?\n",
    "    - насколько переподогнанной является модель?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c701fd3-13e1-4edc-8d19-80921d881bd6",
   "metadata": {},
   "source": [
    "#### Эпохи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049bb1d9-63ba-4366-8ce3-79dfa4bc6ada",
   "metadata": {},
   "source": [
    "```\n",
    "    Самым базовым гиперпараметром является число эпох, хотя в настоящее время этот гиперпараметр чаще заменяют шагами. Гиперпараметр эпох – это число раз, которое вы будете пропускать все тренировочные данные через нейронную сеть во время тренировки.\n",
    "    Помните, что тренировка обходится очень дорого с точки зрения вычислительного времени. Например, если полный проход данных (эпоха) занимает 15 минут, а  мы выполняем 100 эпох, то время тренировки составит 25 часов.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb0a1ef-22e7-4255-8a14-c51a206bd6ec",
   "metadata": {},
   "source": [
    "#### Шаги"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85292aa0-ab7f-4652-acfb-09dbc980ff73",
   "metadata": {},
   "source": [
    "```\n",
    "    Есть и еще один способ повысить точность и сократить время тренировки, а именно путем изменения выборочного распределения тренировочного набора данных. В случае эпох мы думаем о последовательном извлечении пакетов из тренировочных данных. Несмотря на то что мы случайно перетасовываем тренировочные данные в начале каждой эпохи, выборочное распределение остается прежним.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67499b02-8109-4cb8-af7c-baa8aeab6563",
   "metadata": {},
   "source": [
    "<img src=\"images/steps.png\" alt=\"convergence\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3c94c2-8804-4d66-93d1-42c990afe6e3",
   "metadata": {},
   "source": [
    "```\n",
    "    Хотя наш набор данных чаще всего является фиксированным, можно использовать несколько методов, чтобы его изменить и, таким образом, усваивать выборочное распределение, которое подходит для тренировки модели лучше всего. Эти методы таковы:\n",
    "    - регуляризация (dropout);\n",
    "    - пакетная нормализация;\n",
    "    - обогащение (аугментация) данных.\n",
    "    С этой точки зрения мы больше не рассматриваем подачу данных в нейронную сеть как последовательный проход по тренировочным\n",
    "данным, а смотрим на него как на случайный отбор из выборочного распределения. В таком случае шаги относятся к числу пакетов (извлечений), которые мы будем использовать из выборочного распределения тренировочных данных. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa888b67-f119-46e4-a9f3-c60806a9bd1c",
   "metadata": {},
   "source": [
    "```\n",
    "    При добавлении в нейронные сети dropout-слоев мы отсеиваем активации случайно на основе каждой выборки. В дополнение\n",
    "к уменьшению переподгонки нейронной сети мы также изменяем распределение.\n",
    "    С помощью пакетной нормализации мы минимизируем ковариантный сдвиг между пакетами тренировочных данных. Активации изменяют свое значение с помощью стандартизации, подобно тому, как это происходит на входных данных (мы вычитаем среднее значение пакета и делим на стандартное отклонение пакета). Такая нормализация уменьшает колебания в обновлениях модельных параметров. Вдобавок такая нормализация имитирует извлечение из выборочного распределения, представляющего популяционное распределение шире.\n",
    "    С помощью обогащения данных мы создаем новые примеры тем самым меняя распределение.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65265d38-5620-4739-a3ab-9212e101dcfd",
   "metadata": {},
   "source": [
    "#### Размер batch-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecf5e77-6a67-4e5c-b9af-8926cadf1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Стохастический градиентный спуск\n",
    "# Пакетный градиентный спуск\n",
    "# Мини-пакетный градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a459c4d-c104-4d93-9149-005e1d373611",
   "metadata": {},
   "source": [
    "#### Скорость обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800597e6-e8cf-42ec-a228-4bf5a8174faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Малая/Высокая скорость\n",
    "# Затухание\n",
    "# Момент\n",
    "# Адаптивная скорость"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e12acca-bfa8-4279-880f-fb96ecf5a776",
   "metadata": {},
   "source": [
    "```\n",
    "Многие популярные алгоритмы адаптируют скорость усвоения динамически:\n",
    " Adadelta;\n",
    " Adagrad;\n",
    " Adam;\n",
    " AdaMax;\n",
    " AMSGrad;\n",
    " Momentum;\n",
    " Nadam;\n",
    " Nesterov;\n",
    " RMSprop.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1200c4-65c5-4929-a971-be159a586733",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7d66dc7-945e-49c1-bb10-cec2fa1b95d3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27127dc4-7f8a-43a4-8f90-71e4e3c37634",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
