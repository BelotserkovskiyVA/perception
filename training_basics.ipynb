{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0be132-cf48-40d2-a3bc-59af1f8b9a4a",
   "metadata": {},
   "source": [
    "## Содержание\n",
    "```\n",
    "1 Прямой проход и обратное распространение\n",
    "2 Разбиение набора данных\n",
    "3 Нормализация данных\n",
    "4 Валидация и переобучение\n",
    "5 Схождение\n",
    "6 Контрольные точки и ранняя остановка\n",
    "7 Гиперпараметры\n",
    "8 Инвариантность\n",
    "9 Сырые наборы данных\n",
    "10 Сохранение/Восстановление модели\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a69b05-d7fc-48fd-b685-635f8a6edcb7",
   "metadata": {},
   "source": [
    "## Прямой проход и обратное распространение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e097cb-3772-45be-8f85-ab9a9200777b",
   "metadata": {},
   "source": [
    "#### Прямой проход"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af0c34b-0c31-4b95-a35e-8deb6e48a448",
   "metadata": {},
   "source": [
    "<img src=\"images/forward_pass.png\" alt=\"forward\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbf1ad-bbd5-4f3b-8f8c-414ffdbddff7",
   "metadata": {},
   "source": [
    "```\n",
    "    Данные подаются в нейронную сеть пакетами (batch-ами). Пакет может состоять из одного или нескольких выбранных наугад примеров из тренировочных данных.\n",
    "    Тренировочные данные подаются в модель несколько раз. Всякий раз, когда мы подаем все тренировочные данные целиком, это\n",
    "называется эпохой. Каждая эпоха представляет собой отличающуюся случайную перестановку примеров в пакетах – то есть не существует двух эпох с одинаковым порядком следования примеров.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c6ff4-4233-4cc1-9666-89aab00b1edb",
   "metadata": {},
   "source": [
    "#### Историческая справка\n",
    "```\n",
    "    В  ранних нейронных сетях, таких как персептрон и пр., исследователи экспериментировали со способами обновления весов, чтобы получать правильный ответ.\n",
    "    Когда они работали всего с несколькими нейронами и простыми задачами, первым подходом было случайное обновление весов. Кто бы мог подумать, но случайная догадка работала. Однако, такой подход не масштабировался на большое количество нейронов (скажем, тысячи) и реально существующие приложения; на то, чтобы сделать правильную случайную догадку, могли уйти тысячи лет\n",
    "    Следующим логическим шагом было попытаться сделать случайное значение пропорциональным удаленности от правильного значения. Другими словами, чем больше ошибка (удаленнее предсказание), тем больше диапазон случайных значений; и чем ближе, тем меньше диапазон. Это сокращает время поиска (весов нейронной сети) до сотен лет.\n",
    "    Но такой подход не работал с многослойными нейронными сетями. Обнаружилось, что при наличии нескольких слоев эта методика приводит\n",
    "к тому, что \"левая рука\" – один слой – отменяет работу \"правой руки\" – другого слоя.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196b930-f05c-4aa0-a4e1-4314ffb525a0",
   "metadata": {},
   "source": [
    "#### Обратное распространение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc5e7c-a0e3-44c6-ab55-25b03a264ed0",
   "metadata": {},
   "source": [
    "<img src=\"images/back_prop.png\" alt=\"backpropagation\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f8a42d-0a7c-4532-b425-98fb7e017be5",
   "metadata": {},
   "source": [
    "```\n",
    "    После того как каждый пакет тренировочных данных пропущен через модель в прямом направлении и вычислена потеря, потеря распространяется через модель в обратном направлении. Мы идем слой за слоем, обновляя параметры модели (веса и  смещения), начиная с  верхнего слоя (выхода) и  продвигаясь к  нижнему слою (входу).\n",
    "    Общий метод обновления параметров основан на градиентном спуске. Оптимизатор – это имплементация градиентного спуска, задача которого состоит в обновлении параметров для минимизации потери (максимального приближения к  правильному ответу) в последующих пакетах.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575366ae-029d-4288-9d6a-710b8bb3250f",
   "metadata": {},
   "source": [
    "## Разбиение набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6310d9d1-54da-4d5b-8a49-80b9d21ceeca",
   "metadata": {},
   "source": [
    "#### Тренировочный и тестовый наборы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341fea7d-9357-4b40-98fa-45a6de24aa13",
   "metadata": {},
   "source": [
    "<img src=\"images/train_test.png\" alt=\"train_data\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a66464-f5e3-4d09-8fe4-82eed7738ddf",
   "metadata": {},
   "source": [
    "```\n",
    "     По умолчанию будем рассматривать наборы данных, которые достаточно велики и разнообразны, чтобы представлять выборочное распределение (моделируемую популяцию), и очищены (не зашумлены).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea56b50-533e-46be-9715-ee0ac0d4ac3d",
   "metadata": {},
   "source": [
    "```\n",
    "    Имея в своем распоряжении набор данных, следующим шагом будет его разбиение на примеры, которые будут использоваться для тренировки, и те, которые будут использоваться для тестирования (т.н. отложенные). Мы тренируем модель той порцией набора данных, которые являются тренировочными. Если допустить, что тренировочные данные являются хорошим выборочным распределением, то точность на тренировочных данных должна отражать точность, получаемую при развертывании в реально существующей среде (на примерах, не встречавшихся моделью во время тренировки). Но как проверить истинность этого утверждения до того, как модель будет развернута? Отсюда и вытекает предназначение тестовых данных. Мы откладываем часть данных, с помощью которой будем тестировать модель, после того как она будет обучена, чтобы убедиться, что мы получили или не получили нужную точность.\n",
    "    Сколько данных следует откладывать на тренировку и тестирование? Исторически сложилось эмпирическое соотношение 90/10: 90% для тренировки и 10% для тестирования.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a2c4cc-1d44-4311-918e-d1ed62a25104",
   "metadata": {},
   "source": [
    "#### Пример"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e51777-6e02-4b55-8f09-66648da73fce",
   "metadata": {},
   "source": [
    "```\n",
    "    Для классифицирования изображений есть несколько хорошо известных, подготовленных наборов данных, таких как MNIST, CIFAR-10/100*, SVHN, Flowers, Cats vs. Dogs.\n",
    "    Рассмотрим один из них\n",
    "\n",
    "* аббр. от англ. Canadian Institute for Advanced Research – Канадский институт перспективных исследований\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5e93a-aa6f-44be-8181-e957cd210f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# MNIST\n",
    "\n",
    "# Downloading the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./MNIST/train\", train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./MNIST/test\", train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfce968-5896-4ee4-b0ed-42cbe77ee174",
   "metadata": {},
   "source": [
    "```\n",
    "train - 60000 imgs\n",
    "test  - 10000 imgs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d1e656-f3ca-4041-8441-ea231902f2bf",
   "metadata": {},
   "source": [
    "<img src=\"images/MNIST_data.png\" alt=\"mnist_dataset\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1584b4fe-b1a9-4883-91da-1da2f3d429ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(j):\n",
    "    # 5 -> [[0], [0], [0], [0], [0], [1], [0], [0], [0], [0]]\n",
    "    e = np.zeros((10,1))\n",
    "    e[j] = 1.0\n",
    "    return e\n",
    "\n",
    "def reshape_data(data):\n",
    "    features = [np.reshape(x[0][0].numpy(), (784,1)) for x in data]\n",
    "    #print('features\\n', len(features[0]))\n",
    "    labels = [encode_label(y[1]) for y in data]\n",
    "    #print('labels\\n', len(labels[0]))\n",
    "    return zip(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37602235-1f2b-4f66-a882-5e63e1d4142e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
