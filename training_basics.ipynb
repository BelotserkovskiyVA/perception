{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0be132-cf48-40d2-a3bc-59af1f8b9a4a",
   "metadata": {},
   "source": [
    "## Содержание\n",
    "```\n",
    "1 Прямой проход и обратное распространение\n",
    "2 Разбиение набора данных\n",
    "3 Нормализация данных\n",
    "4 Валидация и потеря\n",
    "5 Схождение\n",
    "6 Контрольные точки и ранняя остановка\n",
    "7 Гиперпараметры\n",
    "8 Инвариантность\n",
    "9 Сырые наборы данных\n",
    "10 Сохранение/Восстановление модели\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a69b05-d7fc-48fd-b685-635f8a6edcb7",
   "metadata": {},
   "source": [
    "## 1 Прямой проход и обратное распространение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e097cb-3772-45be-8f85-ab9a9200777b",
   "metadata": {},
   "source": [
    "#### Прямой проход"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af0c34b-0c31-4b95-a35e-8deb6e48a448",
   "metadata": {},
   "source": [
    "<img src=\"images/forward_pass.png\" alt=\"forward\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbf1ad-bbd5-4f3b-8f8c-414ffdbddff7",
   "metadata": {},
   "source": [
    "```\n",
    "    Данные подаются в нейронную сеть пакетами (batch-ами). Пакет может состоять из одного или нескольких выбранных наугад примеров из тренировочных данных.\n",
    "    Тренировочные данные подаются в модель несколько раз. Всякий раз, когда мы подаем все тренировочные данные целиком, это\n",
    "называется эпохой. Каждая эпоха представляет собой отличающуюся случайную перестановку примеров в пакетах – то есть не существует двух эпох с одинаковым порядком следования примеров.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c6ff4-4233-4cc1-9666-89aab00b1edb",
   "metadata": {},
   "source": [
    "#### Историческая справка\n",
    "```\n",
    "    В  ранних нейронных сетях, таких как персептрон и пр., исследователи экспериментировали со способами обновления весов, чтобы получать правильный ответ.\n",
    "    Когда они работали всего с несколькими нейронами и простыми задачами, первым подходом было случайное обновление весов. Кто бы мог подумать, но случайная догадка работала. Однако, такой подход не масштабировался на большое количество нейронов (скажем, тысячи) и реально существующие приложения; на то, чтобы сделать правильную случайную догадку, могли уйти тысячи лет\n",
    "    Следующим логическим шагом было попытаться сделать случайное значение пропорциональным удаленности от правильного значения. Другими словами, чем больше ошибка (удаленнее предсказание), тем больше диапазон случайных значений; и чем ближе, тем меньше диапазон. Это сокращает время поиска (весов нейронной сети) до сотен лет.\n",
    "    Но такой подход не работал с многослойными нейронными сетями. Обнаружилось, что при наличии нескольких слоев эта методика приводит\n",
    "к тому, что \"левая рука\" – один слой – отменяет работу \"правой руки\" – другого слоя.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196b930-f05c-4aa0-a4e1-4314ffb525a0",
   "metadata": {},
   "source": [
    "#### Обратное распространение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc5e7c-a0e3-44c6-ab55-25b03a264ed0",
   "metadata": {},
   "source": [
    "<img src=\"images/back_prop.png\" alt=\"backpropagation\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f8a42d-0a7c-4532-b425-98fb7e017be5",
   "metadata": {},
   "source": [
    "```\n",
    "    После того как каждый пакет тренировочных данных пропущен через модель в прямом направлении и вычислена потеря, потеря распространяется через модель в обратном направлении. Мы идем слой за слоем, обновляя параметры модели (веса и  смещения), начиная с  верхнего слоя (выхода) и  продвигаясь к  нижнему слою (входу).\n",
    "    Общий метод обновления параметров основан на градиентном спуске. Оптимизатор – это имплементация градиентного спуска, задача которого состоит в обновлении параметров для минимизации потери (максимального приближения к  правильному ответу) в последующих пакетах.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575366ae-029d-4288-9d6a-710b8bb3250f",
   "metadata": {},
   "source": [
    "## 2 Разбиение набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6310d9d1-54da-4d5b-8a49-80b9d21ceeca",
   "metadata": {},
   "source": [
    "#### Тренировочный и тестовый наборы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341fea7d-9357-4b40-98fa-45a6de24aa13",
   "metadata": {},
   "source": [
    "<img src=\"images/train_test.png\" alt=\"train_data\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a66464-f5e3-4d09-8fe4-82eed7738ddf",
   "metadata": {},
   "source": [
    "```\n",
    "     По умолчанию будем рассматривать наборы данных, которые достаточно велики и разнообразны, чтобы представлять выборочное распределение (моделируемую популяцию), и очищены (не зашумлены).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea56b50-533e-46be-9715-ee0ac0d4ac3d",
   "metadata": {},
   "source": [
    "```\n",
    "    Имея в своем распоряжении набор данных, следующим шагом будет его разбиение на примеры, которые будут использоваться для тренировки, и те, которые будут использоваться для тестирования (т.н. отложенные). Мы тренируем модель той порцией набора данных, которые являются тренировочными. Если допустить, что тренировочные данные являются хорошим выборочным распределением, то точность на тренировочных данных должна отражать точность, получаемую при развертывании в реально существующей среде (на примерах, не встречавшихся моделью во время тренировки). Но как проверить истинность этого утверждения до того, как модель будет развернута? Отсюда и вытекает предназначение тестовых данных. Мы откладываем часть данных, с помощью которой будем тестировать модель, после того как она будет обучена, чтобы убедиться, что мы получили или не получили нужную точность.\n",
    "    Сколько данных следует откладывать на тренировку и тестирование? Исторически сложилось эмпирическое соотношение 80/20: 80% для тренировки и 20% для тестирования. Но пропорция 90/10 тоже хорошо работает.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a2c4cc-1d44-4311-918e-d1ed62a25104",
   "metadata": {},
   "source": [
    "#### Пример"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e51777-6e02-4b55-8f09-66648da73fce",
   "metadata": {},
   "source": [
    "```\n",
    "    Для классифицирования изображений есть несколько хорошо известных, подготовленных наборов данных, таких как MNIST, CIFAR-10/100*, SVHN, Flowers, Cats vs. Dogs.\n",
    "    Рассмотрим один из них\n",
    "\n",
    "* аббр. от англ. Canadian Institute for Advanced Research – Канадский институт перспективных исследований\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f76445-503a-481e-8d6e-b151f4a2a4b6",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# MNIST\n",
    "\n",
    "# Downloading the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./MNIST/train\", train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./MNIST/test\", train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfce968-5896-4ee4-b0ed-42cbe77ee174",
   "metadata": {},
   "source": [
    "```\n",
    "train_dataset - 60000 imgs\n",
    "test_dataset  - 10000 imgs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d1e656-f3ca-4041-8441-ea231902f2bf",
   "metadata": {},
   "source": [
    "<img src=\"images/MNIST_data.png\" alt=\"mnist_dataset\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193b8858-518e-4813-b89a-24e70afb5842",
   "metadata": {},
   "source": [
    "``` python\n",
    "def encode_label(j):\n",
    "    # 5 -> [[0], [0], [0], [0], [0], [1], [0], [0], [0], [0]]\n",
    "    e = np.zeros((10,1))\n",
    "    e[j] = 1.0\n",
    "    return e\n",
    "\n",
    "def reshape_data(data):\n",
    "    features = [np.reshape(x[0][0].numpy(), (784,1)) for x in data]\n",
    "    #print('features\\n', len(features[0]))\n",
    "    labels = [encode_label(y[1]) for y in data]\n",
    "    #print('labels\\n', len(labels[0]))\n",
    "    return zip(features, labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0397fc6d-524f-468e-b33f-1cc6d91993dd",
   "metadata": {},
   "source": [
    "## 3 Нормализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b2c26c-bc07-4380-afbf-77a42848ff35",
   "metadata": {},
   "source": [
    "#### Нормализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f43cdb5-b0fa-47a0-9525-327c11ea484b",
   "metadata": {},
   "source": [
    "```\n",
    "    Каждое изображение датасета MNIST является 28×28-матрицей целочисленных значений от 0 до 255. Если посмотреть на параметры\n",
    "натренированной модели (веса и смещения), то они представляют очень малые числа, обычно от –1 до 1. Проблема здесь в том, что\n",
    "большие входные значения (вплоть до 255), будут порождать крупные числа по мере их умножения по всем слоям. Поэтому сети потребуется больше времени на то, чтобы усвоить свои оптимальные значения – если она вообще их усвоит.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a1392-71e1-442f-87b0-69eb531c2f91",
   "metadata": {},
   "source": [
    "Поэтому:\n",
    "```python\n",
    "import numpy\n",
    "\n",
    "maxi = np.max(x_train) # 255.0\n",
    "x_train = (x_train / maxi).astype(np.float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161efb5b-745a-410c-9d7a-34979c799fff",
   "metadata": {},
   "source": [
    "#### Стандартизация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea54e93c-f3b5-45f6-9425-05c07e033bfa",
   "metadata": {},
   "source": [
    "```python\n",
    "mean = np.mean(x_train)\n",
    "std = np.std(x_train)\n",
    "x_train = ((x_train – mean) / std).astype(np.float32)\n",
    "\n",
    "# например x_train = ((x_train / 127.5) – 1).astype(np.float32)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd0d39-2f88-4c0e-8ae5-028531ce2c8e",
   "metadata": {},
   "source": [
    "## 4 Валидация и \"потеря\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb5584-18db-48cf-b161-692abeadb8a0",
   "metadata": {},
   "source": [
    "#### Валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b9fca9-91e6-474e-89f2-2b3920474f0c",
   "metadata": {},
   "source": [
    "<img src=\"images/valid.png\" alt=\"validation\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ca97fb-1dd2-4be2-bd65-f0532cdb347e",
   "metadata": {},
   "source": [
    "```\n",
    "    Допустим, тренировка модели занимает несколько часов. Что делать, если мы не хотим ждать до конца тренировки чтобы узнать точность модели? Для этого мы выделяем небольшую часть тренировочных данных, которые называем валидационными данными.\n",
    "    Модель не тренируется с помощью валидационных данных. Вместо этого указанные данные используются после каждой n-ой эпохи для\n",
    "оценивания возможного результата на тестовых данных. Как и тестовые данные, валидационные данные пропускаются через модель\n",
    "без обновления модельных параметров (в режиме предсказательного вывода), после чего измеряются потеря и точность.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef0721-a9b4-48a6-8a74-fc67ca4c313d",
   "metadata": {},
   "source": [
    "```\n",
    "Если набор данных очень мал и  использование еще меньшего объема данных для тренировки оказывает негативное влияние, то можно применить перекрестную валидацию. Вместо того чтобы часть тренировочных данных, на которых модель никогда не будет тренироваться, с самого начала откладывать в сторону, в каждой эпохе выполняется случайная разбивка. В начале каждой эпохи примеры для валидации отбираются в случайном порядке и не используются для тренировки в этой эпохе, а вместо этого используются для валидационного теста. Но поскольку отбор является случайным, некоторые или все примеры будут появляться среди тренировочных данных в других эпохах\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528854cd-ea55-4c5d-b0ff-e9d4a8237d76",
   "metadata": {},
   "source": [
    "<img src=\"images/cross_valid.png\" alt=\"сross_validation\" height=50% width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff3d68b-2443-4667-b9e6-8c7cc8448d8a",
   "metadata": {},
   "source": [
    "#### Потеря"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b206669f-91ca-4592-9588-2f82d45d52fd",
   "metadata": {},
   "source": [
    "```\n",
    "    Ранее все наше внимание было сосредоточено на точности. Но во время тренировки вы увидите еще одну метрику – среднюю по batch-ам потерю (ошибку) как для тренировочных данных, так и для тестовых. В идеале мы хотели бы видеть неуклонное увеличение точности в расчете на\n",
    "эпоху. Но мы также можем увидеть отрезки эпох, для которых точность выходит на плато или даже колеблется.\n",
    "    Важно то, что мы видим стабильное снижение потери. Плато или колебания в этом случае происходят из-за того, что мы находимся\n",
    "рядом с линиями линейной разделимости, или не полностью перешли линию, но приближаемся, о чем свидетельствует уменьшение потери.\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213ac4b9-1d8f-4348-a82e-9be3c9c7931f",
   "metadata": {},
   "source": [
    "```\n",
    "Давайте рассмотрим пример. Допустим, вы создаете классификатор собак и кошек. В выходном слое у вас есть два узла: один для кошек и один для собак. Допустим, что в конкретном batch-е, когда модель неправильно классифицирует собаку как кошку, выходные значения (уровень уверенности) равны 0.6 для кошки и 0.4 для собаки. В последующем batch-е, когда модель снова неправильно классифицирует собаку как кошку, выходные значения равны 0.55 (кошка) и 0.45 (собака). Теперь значения ближе к фундаментальным истинам, и, следовательно, потеря уменьшается, но они все еще не преодолели порог 0.5, поэтому точность пока не изменилась. Затем допустим, что в еще одном последующем пакете выходные значения для изображения собаки равны 0.49 (кошка) и 0.51 (собака); потеря еще больше уменьшилась, и поскольку мы\n",
    "пересекли порог 0.5, точность повысилась.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dab3356-5045-414b-9bb7-d7dc8fbecd25",
   "metadata": {},
   "source": [
    "## 5 Схождение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9cc2b7-80e9-4f3d-9931-d7414094d4af",
   "metadata": {},
   "source": [
    "<img src=\"images/convergence.png\" alt=\"convergence\" height=50% width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0dda43-66c7-49c0-b507-4c37bd0e4aea",
   "metadata": {},
   "source": [
    "```\n",
    "    Ранние предположения о  тренировке заключались в  том, что чем больше раз вводить тренировочные данные в модель, тем выше будет\n",
    "точность. Мы обнаружили, в особенности в более крупных и сложных сетях, что в определенный момент точность будет деградировать. Сегодня мы стремимся достигать схождения на приемлемом локальном оптимуме, основываясь на том, как модель будет использоваться в приложении. Если излишне натренировать нейронную сеть, то может произойти следующее:\n",
    "    1) нейронная сеть становится переподогнанной к тренировочным данным, демонстрируя повышенную точность на тренировочных данных, но показывая деградирующую точность на тестовых данных;\n",
    "    2) в более глубоких нейронных сетях слои будут учиться неравномерно и иметь разные скорости обучения. Отсюда, поскольку\n",
    "некоторые слои продолжают обучаться (работают в направлении схождения), другие уже могут начать расходиться;\n",
    "    3) продолжение тренировки может привести к тому, что нейронная сеть выскочит из одного локального оптимума и начнет сходиться на другом, менее точном.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05314859-1a48-47fd-b2c9-6aa3d7df234d",
   "metadata": {},
   "source": [
    "## 6 Контрольные точки и ранняя остановка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f8b1d8-1c8a-47e5-82d1-764c3ebf7575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
