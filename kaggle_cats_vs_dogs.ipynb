{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torchvision\n",
    "\n",
    "[torchvision](https://github.com/pytorch/vision) - библиотека, содержащая популярные CV датасеты, утилиты для препроцессинга и, самое важное, pre-trained модели для классификации, обученные на [ImageNet](http://image-net.org/).\n",
    "\n",
    "Большая часть потребностей покрывается имеющимися моделями, но если нужна какая-то другая архитектура или нужно решать задачу, отличную от классификации, то хорошую реализацию и веса, скорее всего, получится нагуглить или найти на github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/brodt/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "224x224x3 -> 7x7x2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hxw -> h/32, w/32, 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как достать признаки?\n",
    "\n",
    "- переопределить последний слой так, чтобы он ничего не делал (неплохой вариант, но что, если нужны признаки из внутрненнего слоя?)\n",
    "- написать хук, который будет возвращать признаки (хороший вариант)\n",
    "- покромсать сетку и делать forward pass только для тех слоев, которые нужны (плохой вариант)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 1. Переопределить последний слой\n",
    "\n",
    "***ВНИМАНИЕ 1:*** Серьезная проблема `torchvision` - отсутствие единого интерфейса у моделей. В каждой реализации слои имеют разные имена и при единовременной работе с разными моделями приходится писать обвязку из условий. Если использовать реализации других архитектур, то ситуация только ухудшается\n",
    "\n",
    "***ВНИМАНИЕ 2:*** В отличие от **Keras**, в **PyTorch** не принято делать последним слоем активацию. Нужная функция применяется при написании train / inference кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "dummy_x = torch.randn(3, 224, 224)\n",
    "dummy_x = dummy_x[None,:,:,:] #dummy_x = torch.randn(1, 3, 224, 224)\n",
    "result = model(dummy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "features_model = deepcopy(model)\n",
    "\n",
    "features_model.fc = nn.Identity()\n",
    "\n",
    "dummy_x = torch.randn(1, 3, 224, 224)\n",
    "features = features_model(dummy_x)\n",
    "features_shape = features.data.numpy().shape\n",
    "assert features_shape == (1, 2048), 'expected (1, 2048), but real is {}'.format(features_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 2. forward для нужных слоёв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_map(model, img):\n",
    "    x = model.layer1(img)\n",
    "    x = model.layer2(x)\n",
    "    x = model.layer3(x)\n",
    "    x = model.layer4(x)\n",
    "    return model.avgpool(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 3. Forward hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgpool_features = None\n",
    "\n",
    "def get_features(module, inputs, output):\n",
    "    global avgpool_features   \n",
    "    avgpool_features = output  # np.squeeze(output.data.cpu().numpy(), axis=(2, 3))\n",
    "\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "model.avgpool.register_forward_hook(get_features)\n",
    "\n",
    "dummy_x = torch.randn(3, 224, 224)\n",
    "dummy_x = dummy_x[None,:,:,:] #dummy_x = torch.randn(1, 3, 224, 224)\n",
    "result = model(dummy_x)\n",
    "\n",
    "assert avgpool_features.shape == (1, 2048), 'expected (1, 2048), but real is {}'.format(avgpool_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение на признаках\n",
    "\n",
    "Обучим обычный sklearn-классификатор, которому на вход подадим признаки из нейросети\n",
    "\n",
    "В качестве датасета будем использовать данные конкурса https://www.kaggle.com/c/dogs-vs-cats/data, https://www.tensorflow.org/datasets/catalog/cats_vs_dogs\n",
    "\n",
    "Датасет содержит 25000 изображений кошек и собак, по 12500 каждого класса. Задача: определить, к какому классу относится конкретное изображение\n",
    "\n",
    "Для определения качества моделей будем использовать метрику ROC-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем и подготовим данные. Выделим 30% на валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘kagglecatsanddogs_3367a.zip’ already there; not retrieving.\n",
      "\n",
      "Archive:  kagglecatsanddogs_3367a.zip\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
    "!unzip -f kagglecatsanddogs_3367a.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('PetImages')\n",
    "cat_fnames = [str(p) for p in (data_path / 'Cat').glob('*.jpg')][:1000]\n",
    "dog_fnames = [str(p) for p in (data_path / 'Dog').glob('*.jpg')][:1000]\n",
    "all_names = cat_fnames + dog_fnames\n",
    "labels = np.array([0] * len(cat_fnames) + [1] * len(dog_fnames))\n",
    "\n",
    "train_fnames, val_fnames, y_train, y_val = train_test_split(\n",
    "    all_names, labels, test_size=0.3,\n",
    "    random_state=42, shuffle=True, stratify=labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В **PyTorch** можно удобно работать с данными с помощью классов `Dataset` и `DataLoader`\n",
    "\n",
    "Напишем свой датасет для расчет признаков изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, fnames, shape):\n",
    "        self._fnames = fnames\n",
    "        self._transform = torchvision.transforms.Compose([\n",
    "            \n",
    "            torchvision.transforms.Resize(shape),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fname = self._fnames[index]\n",
    "        img = Image.open(fname).convert('RGB')\n",
    "        img = self._transform(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно как-то рассчитать признаки.\n",
    "\n",
    "Воспользуемся способом с хуком, но чтобы обойтись без глобальной переменной реализуем класс `FeatureExtractor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, model, device='cuda'):\n",
    "        self._model = model\n",
    "        self._avgpool_features = None\n",
    "        self._device = device\n",
    "        self._model.avgpool.register_forward_hook(self._get_features)\n",
    "\n",
    "    def get_dataset_features(self, loader):\n",
    "        self._model.eval().to(self._device)\n",
    "        features = []\n",
    "        with tqdm.tqdm(loader) as pbar:\n",
    "            for sample in pbar:\n",
    "                _ = self._model(sample.to(self._device))\n",
    "                features.append(self._avgpool_features)\n",
    "\n",
    "        return np.concatenate(features)\n",
    "\n",
    "    def _get_features(self, module, inputs, output):\n",
    "        self._avgpool_features = np.squeeze(output.data.cpu().numpy(), axis=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 175/175 [00:16<00:00, 10.37it/s]\n",
      "100%|██████████| 75/75 [00:05<00:00, 12.78it/s]\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 0\n",
    "shape = (224, 224)\n",
    "\n",
    "train_dataset = FeaturesDataset(train_fnames, shape)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "val_dataset = FeaturesDataset(val_fnames, shape)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "extractor = FeatureExtractor(model, device='cuda')\n",
    "\n",
    "train_features = extractor.get_dataset_features(train_loader)\n",
    "val_features = extractor.get_dataset_features(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно взять любой из известных классификаторов и подать найденные признаки на вход\n",
    "\n",
    "Должен получитсься очень хороший ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_auc(y_val, y_pred, model_name):\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    plt.plot(*roc_curve(y_val, y_pred)[:2], label='{} AUC={:.4f}'.format(model_name, auc))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], '--', color='black')\n",
    "    plt.legend(fontsize='large')\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(val_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_auc(y_val, y_pred, model_name='RF')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
